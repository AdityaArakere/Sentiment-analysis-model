{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5eea36e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "416f3571",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(r\"C:\\Users\\aditya.arakere\\Downloads\\IMDB_Dataset.csv\")\n",
    "df2 = pd.read_csv(r\"C:\\Users\\aditya.arakere\\Downloads\\Twitter_data.csv\", encoding='latin-1', header=None, names=['target', 'id', 'date', 'flag', 'user', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c0015aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2[['text', 'target']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f4876be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  target\n",
      "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...       0\n",
      "1  is upset that he can't update his Facebook by ...       0\n",
      "2  @Kenichan I dived many times for the ball. Man...       0\n",
      "3    my whole body feels itchy and like its on fire        0\n",
      "4  @nationwideclass no, it's not behaving at all....       0\n"
     ]
    }
   ],
   "source": [
    "print(df2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4d24228",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['text'] = df2['text'].apply(lambda x: re.sub(r'@\\w+', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64e1b27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  target\n",
      "0   http://twitpic.com/2y1zl - Awww, that's a bum...       0\n",
      "1  is upset that he can't update his Facebook by ...       0\n",
      "2   I dived many times for the ball. Managed to s...       0\n",
      "3    my whole body feels itchy and like its on fire        0\n",
      "4   no, it's not behaving at all. i'm mad. why am...       0\n"
     ]
    }
   ],
   "source": [
    "print(df2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09f3f5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['text'] = df2['text'].apply(lambda x: re.sub(r'http\\S+|www\\S+', '', x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "352557f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  target\n",
      "0    - A that's a bummer.  You shoulda got David ...       0\n",
      "1  is upset that he can't update his Facebook by ...       0\n",
      "2   I dived many times for the ball. Managed to s...       0\n",
      "3    my whole body feels itchy and like its on fire        0\n",
      "4   no, it's not behaving at all. i'm mad. why am...       0\n"
     ]
    }
   ],
   "source": [
    "print(df2.head())\n",
    "# Remove other non-alphanumeric characters and special symbols\n",
    "df2['text'] = df2['text'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n",
    "\n",
    "# Remove extra whitespaces\n",
    "df2['text'] = df2['text'].apply(lambda x: re.sub(r'\\s+', ' ', x.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3834e47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_first = df2.sample(n=4000, random_state=42)\n",
    "\n",
    "df2_last = df2.sample(n=4000, random_state=42)\n",
    "\n",
    "combined_df2 = pd.concat([df2_first, df2_last], ignore_index=True)\n",
    "\n",
    "combined_df2.rename(columns={'target': 'sentiment'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "804fadf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.rename(columns={'review': 'text'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1f2bccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['text'] = df1['text'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n",
    "\n",
    "df1['text'] = df1['text'].apply(lambda x: re.sub(r'\\s+', ' ', x.strip()))\n",
    "\n",
    "df1['text'] = df1['text'].apply(lambda x: re.sub(r'http\\S+|www\\S+', '', x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9893101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 50 rows with positive sentiment\n",
    "positive_df1 = df1[df1['sentiment'] == 'positive'].sample(n=4000, random_state=42)\n",
    "\n",
    "# Select 50 rows with negative sentiment\n",
    "negative_df1 = df1[df1['sentiment'] == 'negative'].sample(n=4000, random_state=42)\n",
    "\n",
    "# Combine the positive and negative DataFrames\n",
    "combined_df1 = pd.concat([positive_df1, negative_df1], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1ebbef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text sentiment\n",
      "0     I dont know how or why this film has a meager ...  positive\n",
      "1     For a long time it seemed like all the good Ca...  positive\n",
      "2     Terry Gilliams and David Peoples teamed up to ...  positive\n",
      "3     What is there to say about an antiestablishmen...  positive\n",
      "4     This movie was made only 48 years after the en...  positive\n",
      "...                                                 ...       ...\n",
      "7995  Fat Girls is among the worst films within the ...  negative\n",
      "7996  The only reason I give it a 2 is that filmogra...  negative\n",
      "7997  Im not going to bother mentioning any of the p...  negative\n",
      "7998  As with most of the reviewers I saw this on St...  negative\n",
      "7999  As a kid I never understood WHY anyone would w...  negative\n",
      "\n",
      "[8000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(combined_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0105f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_final = pd.concat([combined_df1, combined_df2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6ccd6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    text sentiment\n",
      "0      I dont know how or why this film has a meager ...  positive\n",
      "1      For a long time it seemed like all the good Ca...  positive\n",
      "2      Terry Gilliams and David Peoples teamed up to ...  positive\n",
      "3      What is there to say about an antiestablishmen...  positive\n",
      "4      This movie was made only 48 years after the en...  positive\n",
      "...                                                  ...       ...\n",
      "15995  Ooo a manhunt liam sounds fab I dreamt of my w...         4\n",
      "15996  OMG thats a long day Will wave to you later as...         0\n",
      "15997  Late night still at work virus issue hogging r...         0\n",
      "15998  Can you wait to play my song I got kicked out ...         0\n",
      "15999  well i said that cos obviously Shaun lt3s hims...         4\n",
      "\n",
      "[16000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(combined_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "597038bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_final['sentiment'] = combined_final['sentiment'].map({'positive': '1', 4: '1', 'negative': '0', 0: '0'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8620a32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    text sentiment\n",
      "0      I dont know how or why this film has a meager ...         1\n",
      "1      For a long time it seemed like all the good Ca...         1\n",
      "2      Terry Gilliams and David Peoples teamed up to ...         1\n",
      "3      What is there to say about an antiestablishmen...         1\n",
      "4      This movie was made only 48 years after the en...         1\n",
      "...                                                  ...       ...\n",
      "15995  Ooo a manhunt liam sounds fab I dreamt of my w...         1\n",
      "15996  OMG thats a long day Will wave to you later as...         0\n",
      "15997  Late night still at work virus issue hogging r...         0\n",
      "15998  Can you wait to play my song I got kicked out ...         0\n",
      "15999  well i said that cos obviously Shaun lt3s hims...         1\n",
      "\n",
      "[16000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(combined_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4204b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  text sentiment\n",
      "100  Reading some of the other reviews of this film...         1\n",
      "101  The Falcon and the Snowman is the story of two...         1\n",
      "102  Now this is more like it The first movie had s...         1\n",
      "103  I provided location services on the this film ...         1\n",
      "104  br br This film has some really impressive act...         1\n",
      "105  ROLL is a wonderful little film Toby Malone pl...         1\n",
      "106  A quiet sweet and beutifully nostalgic movie o...         1\n",
      "107  Sentimental and naive but undeniably affecting...         1\n",
      "108  The first twothirds of this biopic of fetish m...         1\n",
      "109  STMD is one of the most fun and enjoyable lowb...         1\n",
      "110  Easily one of the best Indian films ever Grant...         1\n",
      "111  amazing movie I saw this movie for the first t...         1\n",
      "112  Just after having moved into his new cottage i...         1\n",
      "113  After gorging myself on a variety of seemingly...         1\n",
      "114  A glacier slide inside a cavernous ice mountai...         1\n",
      "115  While this movie isnt a classic by any stretch...         1\n",
      "116  Pressburger and Powells greatest movie David N...         1\n",
      "117  I recall so many things about seeing this movi...         1\n",
      "118  I dont have words to describe how good this mo...         1\n",
      "119  I viewed The Reader at Sugar which is not an o...         1\n",
      "120  I didnt expect much when I decided to watch th...         1\n",
      "121  Cracking good yarn with all the actors giving ...         1\n",
      "122  It stars war correspondent William Holden sepa...         1\n",
      "123  I thought this movie was absolutely hilarious ...         1\n",
      "124  It is Queen Victorias misfortune to be defined...         1\n",
      "125  This really is a great film Full of love and h...         1\n",
      "126  Im from Romania ill try to speak in English Al...         1\n",
      "127  This animation TV series is simply the best wa...         1\n",
      "128  Lovingly crafted and terribly interesting to w...         1\n",
      "129  This movie is obviously lowbudget filmed in Br...         1\n",
      "130  The key to The 40YearOld Virgin is not merely ...         1\n",
      "131  Strangely erotic schlock Gothic horror that wi...         1\n",
      "132  As i watched Wirey Spindell i couldnt but laug...         1\n",
      "133  The Journey is a very good film Produced in th...         1\n",
      "134  This was a wonderful little American propagand...         1\n",
      "135  First off this is an excellent series though w...         1\n",
      "136  this movie is funny funny funny my favorite qu...         1\n",
      "137  I recently saw this movie in my International ...         1\n",
      "138  If you like your sports movies to be about dig...         1\n",
      "139  For anyone who may not know what a oneactor mo...         1\n",
      "140  Looking for Quo Vadis at my local video store ...         1\n",
      "141  In Hoot Logan Lerman plays Roy Eberhardt the n...         1\n",
      "142  I really liked this movie Of course the idea i...         1\n",
      "143  This was the very first movie I ever saw in my...         1\n",
      "144  Pola X is a beautiful adaption of Herman Melvi...         1\n",
      "145  After learning that her sister Susan is contem...         1\n",
      "146  As I recall my family made a point to stay hom...         1\n",
      "147  I already loved How the Grinch Stole Christmas...         1\n",
      "148  Wow Its hard to put into words my feelings for...         1\n",
      "149  Ive seen The Blob several times and is one of ...         1\n"
     ]
    }
   ],
   "source": [
    "print(combined_final.iloc[100:150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02bb7700",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_csv(r\"C:\\Users\\aditya.arakere\\Downloads\\Reddit_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0ef420e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.rename(columns={'clean_comment': 'text'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba195bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.rename(columns={'category': 'sentiment'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "17c8ed72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3[df3['text'].apply(lambda x: isinstance(x, str))]\n",
    "\n",
    "# Calculate word count for each text\n",
    "df3['word_count'] = df3['text'].apply(lambda x: len(x.split()))\n",
    "\n",
    "# Filter out rows with one or fewer words\n",
    "cleaned_df3 = df3[df3['word_count'] > 1].copy()\n",
    "\n",
    "# Drop the 'word_count' column\n",
    "cleaned_df3.drop('word_count', axis=1, inplace=True)\n",
    "\n",
    "# Assuming df is the DataFrame containing the Reddit dataset\n",
    "df3_rows1 = cleaned_df3[(cleaned_df3['sentiment'] == 0)].sample(n=2000, random_state=42)\n",
    "df3_rows2 = cleaned_df3[(cleaned_df3['sentiment'] == 1)].sample(n=2000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4aa6095c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 text  sentiment\n",
      "0   you think the same lot the same lot the same l...          0\n",
      "1                                      want that meme          0\n",
      "2   what the islamic countries reaction that what ...          0\n",
      "3   everytime someone call bjp patriotic will post...          0\n",
      "4   local news congress begins operation hand palm...          0\n",
      "5                           hubris what will get bjp           0\n",
      "6   why this not the front page fbi introduced flo...          0\n",
      "7                     chantel just got out her cabin           0\n",
      "8                   modi showing expectations reality          0\n",
      "9                       supposedly been arrested cms           0\n",
      "10                                     they made msg           0\n",
      "11                  will never vote for congress bjp           0\n",
      "12                              ootl what this about           0\n",
      "13                                       pikachu jog           0\n",
      "14                  didn get this can someone explain          0\n",
      "15  why were you pro congress before what changed ...          0\n",
      "16  musica jovanotti non capisco come abbia potuto...          0\n",
      "17  when modiji not finding rafale papers should n...          0\n",
      "18          subah baje desh chinta karne lage swamyji          0\n",
      "19                                the search for namu          0\n"
     ]
    }
   ],
   "source": [
    "df3_rows = pd.concat([df3_rows1, df3_rows2], ignore_index=True)\n",
    "print(df3_rows.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "959c95e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_final2 = pd.concat([combined_final, df3_rows], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b8143810",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.read_csv(r\"C:\\Users\\aditya.arakere\\Downloads\\amazon_review_full_csv\\train2.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5577aad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sentiment                                  text2  \\\n",
      "0          3                     more like funchuck   \n",
      "1          5                              Inspiring   \n",
      "2          5  The best soundtrack ever to anything.   \n",
      "3          4                       Chrono Cross OST   \n",
      "4          5                    Too good to be true   \n",
      "\n",
      "                                                text  \n",
      "0  Gave this to my dad for a gag gift after direc...  \n",
      "1  I hope a lot of people hear this cd. We need m...  \n",
      "2  I'm reading a lot of reviews saying that this ...  \n",
      "3  The music of Yasunori Misuda is without questi...  \n",
      "4  Probably the greatest soundtrack in history! U...  \n"
     ]
    }
   ],
   "source": [
    "print(df4.head())\n",
    "df4_custom_order = ['text', 'sentiment']\n",
    "df4_custom_order2 = ['text2', 'sentiment']\n",
    "df4_selected_columns = df4[df4_custom_order]\n",
    "df4_selected_columns2 = df4[df4_custom_order2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d790b283",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aditya.arakere\\AppData\\Local\\Temp\\ipykernel_9976\\1516853839.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df4_selected_columns['sentiment'] = df4_selected_columns['sentiment'].map({5: '1', 4: '1', 3: '2', 2: '0', 1: '0'})\n",
      "C:\\Users\\aditya.arakere\\AppData\\Local\\Temp\\ipykernel_9976\\1516853839.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df4_selected_columns2['sentiment'] = df4_selected_columns2['sentiment'].map({5: '1', 4: '1', 3: '2', 2: '0', 1: '0'})\n"
     ]
    }
   ],
   "source": [
    "df4_selected_columns['sentiment'] = df4_selected_columns['sentiment'].map({5: '1', 4: '1', 3: '2', 2: '0', 1: '0'})\n",
    "df4_selected_columns2['sentiment'] = df4_selected_columns2['sentiment'].map({5: '1', 4: '1', 3: '2', 2: '0', 1: '0'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dbc36d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 text sentiment\n",
      "0   Gave this to my dad for a gag gift after direc...         2\n",
      "1   I hope a lot of people hear this cd. We need m...         1\n",
      "2   I'm reading a lot of reviews saying that this ...         1\n",
      "3   The music of Yasunori Misuda is without questi...         1\n",
      "4   Probably the greatest soundtrack in history! U...         1\n",
      "5   There's a reason this CD is so expensive, even...         1\n",
      "6   This is a self-published book, and if you want...         0\n",
      "7   I was a dissapointed to see errors on the back...         1\n",
      "8   A complete waste of time. Typographical errors...         0\n",
      "9   I guess you have to be a romance novel lover f...         0\n",
      "10  I feel I have to write to keep others from was...         0\n",
      "11  When you hear folks say that they don't make '...         1\n",
      "12  Excellent stockings for long shifts on your fe...         1\n",
      "13  It took almost 3 weeks to recieve the two pair...         2\n",
      "14  sizes are much smaller than what is recomended...         0\n",
      "                                               text sentiment\n",
      "0                                more like funchuck         2\n",
      "1                                         Inspiring         1\n",
      "2             The best soundtrack ever to anything.         1\n",
      "3                                  Chrono Cross OST         1\n",
      "4                               Too good to be true         1\n",
      "5                    There's a reason for the price         1\n",
      "6                                      Buyer beware         0\n",
      "7                           Errors, but great story         1\n",
      "8                                        The Worst!         0\n",
      "9                                         Oh please         0\n",
      "10                             Awful beyond belief!         0\n",
      "11                   A romantic zen baseball comedy         1\n",
      "12                 Lower leg comfort for 12 hours +         1\n",
      "13                 Delivery was very long wait.....         2\n",
      "14  sizes recomended in the size chart are not real         0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aditya.arakere\\AppData\\Local\\Temp\\ipykernel_9976\\1058215010.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df4_selected_columns2.rename(columns={'text2': 'text'}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df4_selected_columns2.rename(columns={'text2': 'text'}, inplace=True)\n",
    "print(df4_selected_columns.head(15))\n",
    "print(df4_selected_columns2.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f4d7b3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4_rows1 = df4_selected_columns[df4_selected_columns['sentiment'] == '0'].sample(n=3000, random_state=42)\n",
    "df4_rows2 = df4_selected_columns[(df4_selected_columns['sentiment'] == '1')].sample(n=3000, random_state=42)\n",
    "df4_rows12 = df4_selected_columns2[df4_selected_columns2['sentiment'] == '0'].sample(n=3000, random_state=42)\n",
    "df4_rows22 = df4_selected_columns2[(df4_selected_columns2['sentiment'] == '1')].sample(n=3000, random_state=42)\n",
    "df4_rows3 = df4_selected_columns[(df4_selected_columns['sentiment'] == '2')].sample(n=5000, random_state=42)\n",
    "df4_rows32 = df4_selected_columns2[(df4_selected_columns2['sentiment'] == '2')].sample(n=5000, random_state=42)\n",
    "df4_rows = pd.concat([df4_rows1, df4_rows2, df4_rows3, df4_rows12, df4_rows22, df4_rows32], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3705a28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text sentiment\n",
      "9500  This book has to do with a boy and a man who a...         2\n",
      "9501  This one didn't have as good of a storyline as...         2\n",
      "9502  Bringing these two together should have been a...         2\n",
      "9503  This company will not ship to Canada! How dumb...         2\n",
      "9504  When it was listed as spiral bound, I expected...         2\n",
      "...                                                 ...       ...\n",
      "9595  Good study guide when the answers were in the ...         2\n",
      "9596  Twisted Sister is an acquired taste - I get it...         2\n",
      "9597  This film is slow and long, but I was in a pat...         2\n",
      "9598  \"Sly Cooper and the Thievius Raccoonus\" is a m...         2\n",
      "9599  The switch is a problem. I had to ad weight to...         2\n",
      "\n",
      "[100 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df4_rows[9500:9600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ad999bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = pd.read_csv(r\"C:\\Users\\aditya.arakere\\Downloads\\amazon_review_polarity_csv\\train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a944bd2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aditya.arakere\\AppData\\Local\\Temp\\ipykernel_9976\\4180166103.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df5_selected_columns['sentiment'] = df5_selected_columns['sentiment'].map({2: '1', 1: '0'})\n",
      "C:\\Users\\aditya.arakere\\AppData\\Local\\Temp\\ipykernel_9976\\4180166103.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df5_selected_columns2['sentiment'] = df5_selected_columns2['sentiment'].map({2: '1', 1: '0'})\n"
     ]
    }
   ],
   "source": [
    "df5_custom_order = ['text', 'sentiment']\n",
    "df5_custom_order2 = ['text2', 'sentiment']\n",
    "\n",
    "df5_selected_columns = df5[df5_custom_order]\n",
    "df5_selected_columns2 = df5[df5_custom_order2]\n",
    "\n",
    "df5_selected_columns['sentiment'] = df5_selected_columns['sentiment'].map({2: '1', 1: '0'})\n",
    "df5_selected_columns2['sentiment'] = df5_selected_columns2['sentiment'].map({2: '1', 1: '0'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "94379786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 text sentiment\n",
      "0   This sound track was beautiful! It paints the ...         1\n",
      "1   I'm reading a lot of reviews saying that this ...         1\n",
      "2   This soundtrack is my favorite music of all ti...         1\n",
      "3   I truly like this soundtrack and I enjoy video...         1\n",
      "4   If you've played the game, you know how divine...         1\n",
      "5   I am quite sure any of you actually taking the...         1\n",
      "6   This is a self-published book, and if you want...         0\n",
      "7   I loved Whisper of the wicked saints. The stor...         1\n",
      "8   I just finished reading Whisper of the Wicked ...         1\n",
      "9   This was a easy to read book that made me want...         1\n",
      "10  A complete waste of time. Typographical errors...         0\n",
      "11  This was a great book,I just could not put it ...         1\n",
      "12  I thought this book was brilliant, but yet rea...         1\n",
      "13  I guess you have to be a romance novel lover f...         0\n",
      "14  I feel I have to write to keep others from was...         0\n",
      "                                                 text sentiment\n",
      "0                      Stuning even for the non-gamer         1\n",
      "1               The best soundtrack ever to anything.         1\n",
      "2                                            Amazing!         1\n",
      "3                                Excellent Soundtrack         1\n",
      "4   Remember, Pull Your Jaw Off The Floor After He...         1\n",
      "5                             an absolute masterpiece         1\n",
      "6                                        Buyer beware         0\n",
      "7                                      Glorious story         1\n",
      "8                                    A FIVE STAR BOOK         1\n",
      "9                       Whispers of the Wicked Saints         1\n",
      "10                                         The Worst!         0\n",
      "11                                         Great book         1\n",
      "12                                         Great Read         1\n",
      "13                                          Oh please         0\n",
      "14                               Awful beyond belief!         0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aditya.arakere\\AppData\\Local\\Temp\\ipykernel_9976\\1815816144.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df5_selected_columns2.rename(columns={'text2': 'text'}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df5_selected_columns2.rename(columns={'text2': 'text'}, inplace=True)\n",
    "print(df5_selected_columns.head(15))\n",
    "print(df5_selected_columns2.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d35a739b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5_rows1 = df5_selected_columns[df5_selected_columns['sentiment'] == '0'].sample(n=5676, random_state=42)\n",
    "df5_rows2 = df5_selected_columns[(df5_selected_columns['sentiment'] == '1')].sample(n=3000, random_state=42)\n",
    "df5_rows12 = df5_selected_columns2[df5_selected_columns2['sentiment'] == '0'].sample(n=3000, random_state=42)\n",
    "df5_rows22 = df5_selected_columns2[(df5_selected_columns2['sentiment'] == '1')].sample(n=3000, random_state=42)\n",
    "df5_rows = pd.concat([df5_rows1, df5_rows2, df5_rows12, df5_rows22], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "217f5513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    text sentiment\n",
      "0      Made in China. Doesn't keep my coffee warm eno...         0\n",
      "1      Hey everyone, its your band buddy vamp again. ...         0\n",
      "2      There is nothing about this puzzle that is ple...         0\n",
      "3      I bought this set as I wanted a cheap wooden s...         0\n",
      "4      This book is a great introduction into casino ...         0\n",
      "...                                                  ...       ...\n",
      "14671                                       Caesar three         1\n",
      "14672                                A Handy Resource...         1\n",
      "14673                          Perfect part for my needs         1\n",
      "14674                                    Could Be Better         1\n",
      "14675                                 Jug Stompers excel         1\n",
      "\n",
      "[14676 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df5_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "99fc12a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_final3 = pd.concat([df4_rows, df5_rows], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "77cb7ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_final4 = pd.concat([combined_final2, combined_final3], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c54d7a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = pd.read_csv(r\"C:\\Users\\aditya.arakere\\Downloads\\all-data.csv\", encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f7651e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6_custom_order = ['text', 'sentiment']\n",
    "df6_selected_columns = df6[df6_custom_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "523ab273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text sentiment\n",
      "0  According to Gran , the company has no plans t...         2\n",
      "1  Technopolis plans to develop in stages an area...         2\n",
      "2  The international electronic industry company ...         0\n",
      "3  With the new production plant the company woul...         1\n",
      "4  According to the company 's updated strategy f...         1\n"
     ]
    }
   ],
   "source": [
    "df6_selected_columns['sentiment'] = df6_selected_columns['sentiment'].map({\"positive\": '1', \"negative\": '0', \"neutral\": \"2\"})\n",
    "print(df6_selected_columns.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b96c05dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6_rows1 = df6_selected_columns[df6_selected_columns['sentiment'] == '0'].sample(n=500, random_state=42)\n",
    "df6_rows2 = df6_selected_columns[(df6_selected_columns['sentiment'] == '1')].sample(n=500, random_state=42)\n",
    "df6_rows3 = df6_selected_columns[df6_selected_columns['sentiment'] == '2'].sample(n=1000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f93dc605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text sentiment\n",
      "0     The company decided at the end of 2008 to temp...         0\n",
      "1     down to EUR5 .9 m H1 '09 3 August 2009 - Finni...         0\n",
      "2     The steelmaker said that the drop in profit wa...         0\n",
      "3     Finland-based Stockmann Group has closed seven...         0\n",
      "4     Operating loss before non-recurring items was ...         0\n",
      "...                                                 ...       ...\n",
      "1995  The casing comprises a first side casing membe...         2\n",
      "1996  According to Seikku , the retail sector in Fin...         2\n",
      "1997  M-real Corporation Stock Exchange Release 27 A...         2\n",
      "1998  At CapMan Haavisto will be responsible for Gro...         2\n",
      "1999  The name of the newspaper publishing and print...         2\n",
      "\n",
      "[2000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df6_rows = pd.concat([df6_rows1, df6_rows2, df6_rows3], ignore_index=True)\n",
    "print(df6_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f56d925a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df7 = pd.read_csv(r\"C:\\Users\\aditya.arakere\\Downloads\\amazon_reviews.csv\", encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9276fb5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 text sentiment\n",
      "0                                          No issues.         1\n",
      "1   Purchased this for my device, it worked as adv...         1\n",
      "2   it works as expected. I should have sprung for...         1\n",
      "3   This think has worked out great.Had a diff. br...         1\n",
      "4   Bought it with Retail Packaging, arrived legit...         1\n",
      "5   It's mini storage.  It doesn't do anything els...         1\n",
      "6   I have it in my phone and it never skips a bea...         1\n",
      "7   It's hard to believe how affordable digital ha...         1\n",
      "8   Works in a HTC Rezound.  Was running short of ...         1\n",
      "9   in my galaxy s4, super fast card, and am total...         1\n",
      "10  I like this SD Card because it can take music ...         1\n",
      "11  It works, but file writes are a bit slower tha...         2\n",
      "12      THE NAME OF ITSELF SPEAKS OUT. GO SANDISK GO!         1\n",
      "13  Solid SDHC card that is fast (at reading and w...         1\n",
      "14  Heard that the card's write speed is insuffici...         1\n",
      "15  I bought this to use with my go pro hero 3 bla...         1\n",
      "16  got this because i had a 2 GB one that filled ...         1\n",
      "17  Class 10 Speed Rating for Seamless Full HD Vid...         1\n",
      "18  The read and write speeds are better than the ...         1\n",
      "19  This works with the NL1520.  No video stutteri...         1\n",
      "20  Works as expected.  High transfer speed.  Nice...         1\n",
      "21  Works great in a Samsung Galaxy S3.  Formatted...         1\n",
      "22  SanDisk never disappoints. As always SanDisk p...         1\n",
      "23  Good price, works flawless in my Samsung S4! N...         1\n",
      "24  San disk is hard to beat.  You will pay more f...         1\n",
      "25  Installed in my Blackberry Q10 SQN100-1 and fo...         1\n",
      "26  I just received my card, it is the class 10 64...         1\n",
      "27  Stuck it in my S2, formatted in settings, work...         1\n",
      "28  I purchased two of these one for my Samsung ta...         1\n",
      "29  As advertised, specs match.  As long as the de...         1\n",
      "30  This item is great!  I can't believe how small...         1\n",
      "31  I've been trying for a while to get a hold of ...         1\n",
      "32  I bought 2 of those SanDisk 32 GB microSD , us...         0\n",
      "33  The memory card is an excellent condition and ...         1\n",
      "34  I've got a couple of these in varying sizes. I...         1\n",
      "35  I only had 8 gigs of memory on my Note 2 and w...         1\n",
      "36  Bought it for my Surface Pro. I've had it in t...         1\n",
      "37  I would recommend this card to everyone.Data T...         1\n",
      "38  I bougth this micro SD card after some trubles...         0\n",
      "39  Using this in a contout gps camera,  don't was...         1\n",
      "40  This is a fantastic little drive, has all the ...         1\n",
      "41  I am very happy with this Micro SD.  I could t...         1\n",
      "42  I've purchased several of these little babies ...         1\n",
      "43  Ordered this for a Galaxy S3.  Lasted a few mo...         0\n",
      "44  more like 8mb/s in my Note 10.1 and that's usi...         1\n",
      "45  not much to say other than plug and play, good...         1\n",
      "46  A new camcorder required fast SD (micro) and S...         1\n",
      "47  This tiny marvel does what it claims.  The onl...         1\n",
      "48  It does the job and the price was right. It ca...         1\n",
      "49  I used this for a few months in my phone, then...         0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aditya.arakere\\AppData\\Local\\Temp\\ipykernel_9976\\2945974980.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df7_selected_columns['sentiment'] = df7_selected_columns['sentiment'].map({1: '0', 2: '0', 3: \"2\", 4: \"1\", 5: \"1\"})\n"
     ]
    }
   ],
   "source": [
    "df7_custom_order = ['text', 'sentiment']\n",
    "df7_selected_columns = df7[df7_custom_order]\n",
    "df7_selected_columns['sentiment'] = df7_selected_columns['sentiment'].map({1: '0', 2: '0', 3: \"2\", 4: \"1\", 5: \"1\"})\n",
    "print(df7_selected_columns.head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f7ccb9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df7_rows1 = df7_selected_columns[df7_selected_columns['sentiment'] == '0'].sample(n=324, random_state=42)\n",
    "df7_rows2 = df7_selected_columns[(df7_selected_columns['sentiment'] == '1')].sample(n=3000, random_state=42)\n",
    "df7_rows3 = df7_selected_columns[df7_selected_columns['sentiment'] == '2'].sample(n=142, random_state=42)\n",
    "df7_rows = pd.concat([df7_rows1, df7_rows2, df7_rows3], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e7bd8627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text sentiment\n",
      "0     I have had the 32gb in my Galaxy S3 for almost...         0\n",
      "1     Sandisk has the name but in my experience the ...         0\n",
      "2     I just called Sandisk and they say they have a...         0\n",
      "3     I routinely use SDXC cards up to 128GB, and th...         0\n",
      "4     In real-life use--copying compressed files to ...         0\n",
      "...                                                 ...       ...\n",
      "3461  I got a Samsung Galaxy Tab 7 2 and I got this ...         2\n",
      "3462  I use it for my galaxy s4 and this card crashe...         2\n",
      "3463  Reliable and inexpensive. However, it's quite ...         2\n",
      "3464  There is a known issue with a batch of these c...         2\n",
      "3465  Have only transfered some pictures and music s...         2\n",
      "\n",
      "[3466 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df7_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bb99b4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_final5 = pd.concat([df6_rows, df7_rows], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c0a8406e",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_final6 = pd.concat([combined_final4, combined_final5], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "46ad6b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df8 = pd.read_csv(r\"C:\\Users\\aditya.arakere\\Downloads\\go_emotions.csv\", encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c95a5593",
   "metadata": {},
   "outputs": [],
   "source": [
    "df9 = pd.read_csv(r\"C:\\Users\\aditya.arakere\\Downloads\\supervised_email.csv\", encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e25cc0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 text sentiment\n",
      "0      You do right, if you don't care then fuck 'em!         2\n",
      "1   [NAME] was nowhere near them, he was by the Fa...         2\n",
      "2   I have, and now that you mention it, I think t...         2\n",
      "3                               BUT IT'S HER TURN! /s         2\n",
      "4                                   Build a wall? /jk         2\n",
      "5   One time my 1 stopped right in 91st, I was abl...         2\n",
      "6   This video doesn't even show the shoes he was ...         2\n",
      "7             this definitely fits in r/BoneAppleTea.         2\n",
      "8                                  RemindMe! 3 months         2\n",
      "9    but it's [NAME] saying it so sorta disappointing         2\n",
      "10       Something Something Something, space of aids         2\n",
      "11  I've probably put a couple hundred miles on my...         2\n",
      "12  What evidence at all shows that [NAME] was an ...         2\n",
      "13  If [NAME] has similar role to end year then no...         2\n",
      "14  [NAME] is cheaper too. If we would have kept [...         2\n",
      "15  This guy is basically the referee in parliamen...         2\n",
      "16                You should dm her and say I'm sorry         2\n",
      "17  I feel this. For me since Iâm using those ga...         2\n",
      "18  10 life hacks you didn't know you needed in yo...         2\n",
      "19                           That's why it's only 20$         2\n",
      "20  Just wait. Wait for the false promise. Wait fo...         2\n",
      "21   She wants to connect, alright. With your wallet.         2\n",
      "22  Nice! You and her would get along i bet. She l...         2\n",
      "23  [NAME] to [NAME]: \"Don't try and tell me how t...         2\n",
      "24           My fans on patreon will be rewarded soon         2\n",
      "25  What does your statement even mean? It's a gam...         2\n",
      "26                                          You okay?         2\n",
      "27  Talks of contributing proportionately, wants p...         2\n",
      "28                You should eat real cake today too!         2\n",
      "29  It's also had derogatory meaning for nearly 40...         2\n",
      "30                        [NAME]: \"She seems useless\"         2\n",
      "31                      Now you ruined the surprise!\"         2\n",
      "32                      Think you mean this Labour MP         2\n",
      "33                I have already, what's your point?          2\n",
      "34  [NAME] just needs to split it up more resting ...         2\n",
      "35  Umm... I do it everyday since I was 13 and Iâ...         2\n",
      "36                             KILLING IN THE NAME OF         2\n",
      "37                  [NAME] the people must be warned.         2\n",
      "38  I'd watch it without a doubt. I'm especially i...         2\n",
      "39  Be careful with the Washington Times. It's not...         2\n",
      "40              is a recent article interesting read.         2\n",
      "41                         ...by the same person even         2\n",
      "42  Iq designed by the military to see who would b...         2\n",
      "43   RTD lines are free in Denver tonight. Stay safe.         2\n",
      "44  It's a tool that idiots install so they can ta...         2\n",
      "45  Without fail saying \"moist panties\" makes ever...         2\n",
      "46  This is the most pleasant debate Iâve ever h...         2\n",
      "47  What's that like? Like what's the thought proc...         2\n",
      "48  I feel like I saw this literally last week, th...         2\n",
      "49  Theyâre looking at her like they wish theyâ...         2\n"
     ]
    }
   ],
   "source": [
    "df8_custom_order = ['text', 'sentiment']\n",
    "df8_selected_columns = df8[df8_custom_order]\n",
    "df8_selected_columns['sentiment'] = df8_selected_columns['sentiment'].map({1: '2'})\n",
    "print(df8_selected_columns.head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "977a6505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 text sentiment\n",
      "0          You do right if you dont care then fuck em         2\n",
      "1     NAME was nowhere near them he was by the Falcon         2\n",
      "2   I have and now that you mention it I think tha...         2\n",
      "3                                  BUT ITS HER TURN s         2\n",
      "4                                     Build a wall jk         2\n",
      "5   One time my 1 stopped right in 91st I was able...         2\n",
      "6   This video doesnt even show the shoes he was w...         2\n",
      "7               this definitely fits in rBoneAppleTea         2\n",
      "8                                   RemindMe 3 months         2\n",
      "9       but its NAME saying it so sorta disappointing         2\n",
      "10        Something Something Something space of aids         2\n",
      "11  Ive probably put a couple hundred miles on my ...         2\n",
      "12  What evidence at all shows that NAME was an ac...         2\n",
      "13  If NAME has similar role to end year then no w...         2\n",
      "14  NAME is cheaper too If we would have kept NAME...         2\n",
      "15  This guy is basically the referee in parliamen...         2\n",
      "16                 You should dm her and say Im sorry         2\n",
      "17  I feel this For me since Iâm using those gamet...         2\n",
      "18  10 life hacks you didnt know you needed in you...         2\n",
      "19                              Thats why its only 20         2\n",
      "20  Just wait Wait for the false promise Wait for ...         2\n",
      "21      She wants to connect alright With your wallet         2\n",
      "22  Nice You and her would get along i bet She lov...         2\n",
      "23    NAME to NAME Dont try and tell me how to defend         2\n",
      "24           My fans on patreon will be rewarded soon         2\n",
      "25  What does your statement even mean Its a game ...         2\n",
      "26                                           You okay         2\n",
      "27  Talks of contributing proportionately wants pr...         2\n",
      "28                 You should eat real cake today too         2\n",
      "29  Its also had derogatory meaning for nearly 400...         2\n",
      "30                             NAME She seems useless         2\n",
      "31                        Now you ruined the surprise         2\n",
      "32                      Think you mean this Labour MP         2\n",
      "33                    I have already whats your point         2\n",
      "34  NAME just needs to split it up more resting hi...         2\n",
      "35  Umm I do it everyday since I was 13 and Iâm fi...         2\n",
      "36                             KILLING IN THE NAME OF         2\n",
      "37                     NAME the people must be warned         2\n",
      "38  Id watch it without a doubt Im especially inte...         2\n",
      "39  Be careful with the Washington Times Its not e...         2\n",
      "40               is a recent article interesting read         2\n",
      "41                            by the same person even         2\n",
      "42  Iq designed by the military to see who would b...         2\n",
      "43     RTD lines are free in Denver tonight Stay safe         2\n",
      "44  Its a tool that idiots install so they can tag...         2\n",
      "45  Without fail saying moist panties makes every ...         2\n",
      "46  This is the most pleasant debate Iâve ever had...         2\n",
      "47  Whats that like Like whats the thought process...         2\n",
      "48  I feel like I saw this literally last week the...         2\n",
      "49  Theyâre looking at her like they wish theyâd o...         2\n"
     ]
    }
   ],
   "source": [
    "df8_selected_columns['text'] = df8_selected_columns['text'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n",
    "\n",
    "df8_selected_columns['text'] = df8_selected_columns['text'].apply(lambda x: re.sub(r'\\s+', ' ', x.strip()))\n",
    "\n",
    "df8_selected_columns['text'] = df8_selected_columns['text'].apply(lambda x: re.sub(r'http\\S+|www\\S+', '', x))\n",
    "print(df8_selected_columns.head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "69628a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df8_rows = df8_selected_columns[df8_selected_columns['sentiment'] == '2'].sample(n=5000, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "16a46d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 text sentiment\n",
      "0               THIS MEETING WILL TAKE PLACE IN 30C1          2\n",
      "1    Did you get our trunkline STX deal booked las...         2\n",
      "2   Just got back in the office. Richard and I spo...         2\n",
      "3    Can you forward Cary's old industrials info t...         2\n",
      "4   There has been a reduction in flow for the Jun...         2\n",
      "5                                   -----------------         2\n",
      "6   Whoever is doing gas settlements should know w...         2\n",
      "7   YEA MAN......................YOU JUST SAY THE ...         2\n",
      "8   we called you back but you weren't there. Lets...         2\n",
      "9    Hey patrice - we will get you a price the Nov...         2\n",
      "10  El paso came back with GD.06. Kay is going cal...         2\n",
      "11   AOS IS EXPECTED TO BE UNCHANGED FOR THE WEEKEND          2\n",
      "12  Anytime before 11:00 a.m. and anytime after 1:...         2\n",
      "13  Could you get a name of the person who was inq...         2\n",
      "14  Hi guys - Just a heads up that the copy machin...         2\n",
      "15                 Brian these are the actual rates.          2\n",
      "16  you might dress it up a bit and include a disc...         2\n",
      "17  See attached. Let me know if you have questions.          2\n",
      "18                The conf. room is as follows: 6716          2\n",
      "19   T.Jae Black East Power Trading Assistant to K...         2\n",
      "20              http:www.bol.ucla.edurahjr79ninja.htm         2\n",
      "21   If your job ever gets you down, just click th...         2\n",
      "22  Attached is the Weekly Deal Report for 112201....         2\n",
      "23                                            FYI...          2\n",
      "24                          I will be there. Grigsby          2\n",
      "25      Added 1bcf injections. Total month is 6.5bcf          2\n",
      "26  I figured it out. We can get in through the In...         2\n",
      "27  C:Documents and SettingsddavisLocal SettingsTe...         2\n",
      "28                                 I listen to both.          2\n",
      "29   Nicole Mendez Sr. Administrative Assistant EW...         2\n",
      "30  I don't. Why did you think about me when you h...         2\n",
      "31      Robert B Cothran Enron Americas 713-853-3478          2\n",
      "32                                            Nicole          2\n",
      "33      This should be addressed to Mark Dana Davis.          2\n",
      "34  Lisa, I have submitted 3 checks related to Asp...         2\n",
      "35  I was thinking about coming over for lunch but...         2\n",
      "36          http:www.isdelight.comidaspse1.asp?id0621         2\n",
      "37            You are able to get online now, Duck??          2\n",
      "38            You still buying that lipstick for me?          2\n",
      "39                             Mark this is for you.          2\n",
      "40       Hey, I just got back from lunch. What's up?          2\n",
      "41                            Dana, This is for you.          2\n",
      "42                             http:www.familyfeud.tv         2\n",
      "43                                           Really?          2\n",
      "44                   Can we move lunch to Wednesday?          2\n",
      "45  Gracias! Nicole Mendez Sr. Administrative Assi...         2\n",
      "46               I haven't heard from you in a while.         2\n",
      "47                                        FRANK!!!!!          2\n",
      "48  All those Houston Chronicle articles that you ...         2\n",
      "49                               maryce@springisd.org         2\n"
     ]
    }
   ],
   "source": [
    "df9_custom_order = ['text', 'sentiment']\n",
    "df9_selected_columns = df9[df9_custom_order]\n",
    "df9_selected_columns['sentiment'] = df9_selected_columns['sentiment'].map({\"neu\": '2'})\n",
    "print(df9_selected_columns.head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c5cecb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 text sentiment\n",
      "0                THIS MEETING WILL TAKE PLACE IN 30C1         2\n",
      "1   Did you get our trunkline STX deal booked last...         2\n",
      "2   Just got back in the office Richard and I spok...         2\n",
      "3   Can you forward Carys old industrials info to ...         2\n",
      "4   There has been a reduction in flow for the Jun...         2\n",
      "5                                                             2\n",
      "6   Whoever is doing gas settlements should know w...         2\n",
      "7   YEA MANYOU JUST SAY THE TIMEI GOT HERE AT 630 ...         2\n",
      "8   we called you back but you werent there Lets t...         2\n",
      "9   Hey patrice we will get you a price the NovMar...         2\n",
      "10  El paso came back with GD06 Kay is going call ...         2\n",
      "11    AOS IS EXPECTED TO BE UNCHANGED FOR THE WEEKEND         2\n",
      "12  Anytime before 1100 am and anytime after 130 p...         2\n",
      "13  Could you get a name of the person who was inq...         2\n",
      "14  Hi guys Just a heads up that the copy machine ...         2\n",
      "15                   Brian these are the actual rates         2\n",
      "16  you might dress it up a bit and include a disc...         2\n",
      "17     See attached Let me know if you have questions         2\n",
      "18                   The conf room is as follows 6716         2\n",
      "19  TJae Black East Power Trading Assistant to Kev...         2\n",
      "20                   httpwwwboluclaedurahjr79ninjahtm         2\n",
      "21  If your job ever gets you down just click the ...         2\n",
      "22  Attached is the Weekly Deal Report for 112201 ...         2\n",
      "23                                                FYI         2\n",
      "24                            I will be there Grigsby         2\n",
      "25         Added 1bcf injections Total month is 65bcf         2\n",
      "26  I figured it out We can get in through the Int...         2\n",
      "27  CDocuments and SettingsddavisLocal SettingsTem...         2\n",
      "28                                   I listen to both         2\n",
      "29  Nicole Mendez Sr Administrative Assistant EWS ...         2\n",
      "30  I dont Why did you think about me when you hea...         2\n",
      "31         Robert B Cothran Enron Americas 7138533478         2\n",
      "32                                             Nicole         2\n",
      "33        This should be addressed to Mark Dana Davis         2\n",
      "34  Lisa I have submitted 3 checks related to Aspe...         2\n",
      "35  I was thinking about coming over for lunch but...         2\n",
      "36               httpwwwisdelightcomidaspse1aspid0621         2\n",
      "37                You are able to get online now Duck         2\n",
      "38              You still buying that lipstick for me         2\n",
      "39                               Mark this is for you         2\n",
      "40            Hey I just got back from lunch Whats up         2\n",
      "41                               Dana This is for you         2\n",
      "42                                httpwwwfamilyfeudtv         2\n",
      "43                                             Really         2\n",
      "44                     Can we move lunch to Wednesday         2\n",
      "45  Gracias Nicole Mendez Sr Administrative Assist...         2\n",
      "46                 I havent heard from you in a while         2\n",
      "47                                              FRANK         2\n",
      "48  All those Houston Chronicle articles that you ...         2\n",
      "49                                 marycespringisdorg         2\n"
     ]
    }
   ],
   "source": [
    "df9_selected_columns['text'] = df9_selected_columns['text'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n",
    "\n",
    "df9_selected_columns['text'] = df9_selected_columns['text'].apply(lambda x: re.sub(r'\\s+', ' ', x.strip()))\n",
    "print(df9_selected_columns.head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "56cb9bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df9_rows = df9_selected_columns[df9_selected_columns['sentiment'] == '2'].sample(n=9000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cfbc1eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_final7 = pd.concat([df8_rows, df9_rows], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "eb456367",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_final8 = pd.concat([combined_final6, combined_final7], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "024b91c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_final8.to_csv('combined_dataset12.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ee8704",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
